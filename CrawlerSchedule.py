from Crawler.Realtor_Spider import RealtorSpider
from Service.Manage_DataBase import Manage_DataBase 
import time
import os
mongo_uri = os.getenv(
    "MONGO_URI",
    "mongodb://mongo:27017/" 
)
def run_daily_update():
    db_manager = Manage_DataBase(db_uri=mongo_uri)
    regions = db_manager.db.crawl_regions.find({"active": True})
    
    for region in regions:
        print(f"å¼€å§‹æŠ“å–åŒºåŸŸ: {region['name']}")
        collect_data_for_region(region)
        
def collect_data_for_region(region):
    spider = RealtorSpider(db_uri=mongo_uri)
    db_manager = Manage_DataBase(db_uri=mongo_uri) # ç§»åˆ°å¾ªç¯å¤–ï¼Œå¤ç”¨è¿æ¥
    continue_fetching = True
    page = 1
    
    while continue_fetching:
        data, continue_fetching = spider.fetch_data(region["coords"], page=page)
        
        if data and data.get("Results"):
            db_manager.process_and_save_listings(data)
            print(f"âœ… åŒºåŸŸ {region['name']} ç¬¬ {page} é¡µæ›´æ–°å®Œæˆ")
            page += 1
            time.sleep(10) # ä»…åœ¨æˆåŠŸæŠ“å–åå»¶è¿Ÿï¼Œé¿å…è¢« Realtor.ca å°ç¦
        else:
            # å¦‚æœæŸé¡µå¤±è´¥ï¼Œæ‰“å°å…·ä½“ä¿¡æ¯å¹¶é€€å‡ºå½“å‰åŒºåŸŸ
            print(f"ğŸ›‘ åŒºåŸŸ {region['name']} ç¬¬ {page} é¡µæŠ“å–ä¸­æ–­æˆ–æ— ç»“æœ")
            break
if __name__ == "__main__":
    run_daily_update()
